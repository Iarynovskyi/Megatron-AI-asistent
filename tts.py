import time

import sounddevice as sd
import torch
#from pygments.lexers.sql import language_re

language = 'ua'
model_id = 'v4_ua'
#language = 'ru'
#model_id = 'ru_v3'
sample_rate = 48000  # 48000
speaker = 'mykyta'  # aidar, baya, kseniya, xenia, random
put_accent = True
put_yo = True
device = torch.device('cpu')  # cpu –∏–ª–∏ gpu
#text = "–•–∞—É–¥–∏ –•–æ, –¥—Ä—É–∑—å—è!!!"

model, _ = torch.hub.load(repo_or_dir='snakers4/silero-models',
                          model='silero_tts',
                          language=language,
                          speaker=model_id)
model.to(device)

def split_text(text, max_length=800):
    words = text.split()
    chunks = []
    current_chunk = []
    current_length = 0

    for word in words:
        if current_length + len(word) + 1 > max_length:
            chunks.append(" ".join(current_chunk))
            current_chunk = [word]
            current_length = len(word)
        else:
            current_chunk.append(word)
            current_length += len(word) + 1

    # –î–æ–¥–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, —è–∫—â–æ –≤—ñ–Ω –Ω–µ –ø–æ—Ä–æ–∂–Ω—ñ–π
    if current_chunk:
        chunks.append(" ".join(current_chunk))

    return chunks
def va_speak(what: str):
    if not what:
        print("–ü–æ–º–∏–ª–∫–∞: –ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—É –¥–ª—è –æ–∑–≤—É—á–µ–Ω–Ω—è.")
        return

    text_chunks = split_text(what)

    for i, chunk in enumerate(text_chunks):
        try:
            print(f"–û–±—Ä–æ–±–∫–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ {i+1}/{len(text_chunks)}: {chunk[:100]}...")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            audio = model.apply_tts(text=chunk + "..",
                                    speaker=speaker,
                                    sample_rate=sample_rate,
                                    put_accent=put_accent,
                                    put_yo=put_yo)

            # –í—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –∞—É–¥—ñ–æ
            sd.play(audio, sample_rate * 1.05)
            time.sleep((len(audio) / sample_rate) + 0.5)
            sd.stop()

        except Exception as e:
            print(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞: {e} –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ {i+1}/{len(text_chunks)}")
            continue

'''
from TTS.api import TTS

device = "cuda" if torch.cuda.is_available() else "cpu"

# List available üê∏TTS1 models
print(TTS().list_models())

# Init TTS1
tts = TTS("tts_models/multilingual/multi-dataset/xtts.py").to(device)

# Run TTS1
# ‚ùó Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
wav = tts.tts(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en")
# Text to speech to a file
tts.tts_to_file(text="Hello world!", speaker_wav="my/cloning/audio.wav", language="en", file_path="output.wav")

'''